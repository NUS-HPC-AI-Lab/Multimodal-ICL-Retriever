hydra:
  job:
    chdir: false
task_name: coco
model_name: 'openai/clip-vit-large-patch14'
pretrained_model_path: null     # the pretrained local model to load (for CEIL, EPR model is used as initialization)

# parameters needed to initialize the training arguments, see https://huggingface.co/docs/transformers/v4.26.0/en/main_classes/trainer#transformers.TrainingArguments
training_args:
  _target_: transformers.TrainingArguments
  run_name: msier
  output_dir: m_icl_50_1_coco_1e-5 # the output directory to save the trained model, will be used in the evaluation
  do_train: true
  do_eval: true
  learning_rate: 1e-5
  warmup_steps: 180
  num_train_epochs: 30
  per_device_train_batch_size: 50
  per_device_eval_batch_size: 50
  gradient_accumulation_steps: 1
  evaluation_strategy: steps
  eval_steps: 100
  logging_steps: 10
  save_total_limit: 3
  save_strategy: steps
  save_steps: 900
  metric_for_best_model: eval_loss
  load_best_model_at_end: true

# parameters needed to initialize the input dataset
dataset_reader:
  _target_: src.dataset_readers.training_dsr.TrainingDatasetReader
  task_name: ${task_name}
  model_name: ${model_name}
  field: q
  dataset_path: coco_train/scorer.json
  ds_size: null

# parameters needed to initialize the index reader
index_reader:
  _target_: src.dataset_readers.index_dsr.IndexDatasetReader
  task_name: ${task_name}
  model_name: ${model_name}
  field: qa
  dataset_split: null           # one of `dataset_path` and `dataset_split` must be set
  dataset_path: coco_train/index_dataset.json
  ds_size: null

# parameters needed to initialize the batch collector
collector:
  hard_neg_per_step: 1          # for training EPR, the number of hard negatives in each step
  pos_topk: 5                   # for training EPR, the number of candidates defined as positive
  neg_topk: -5                  # for training EPR, the number of candidates defined as negatives

# parameters needed to initialize the bi-encoder model
model_config:
  _target_: src.models.biencoder.BiEncoderConfig
  q_model_name: ${model_name}   # the encoder to encode input examples
  ctx_model_name: ${model_name} # the encoder to encode in-context examples
  ctx_no_grad: true             # whether to freeze the context (in-context example) encoder, we share the two encoders for EPR and fix the ctx encoder for CEIL
  norm_embed: true             # whether to normalize the embedding after q and ctx encoder

